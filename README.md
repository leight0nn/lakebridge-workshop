# Lakebridge Workshop: SQL Server to Databricks Migration

### *Comprehensive hands-on workshop extending [Databricks Labs Lakebridge](https://github.com/databrickslabs/lakebridge) for practical data warehouse migration training*

![Databricks Labs Lakebridge White](/docs/lakebridge/static/img/lakebridge-lockup-white-background.svg)

[![Workshop Build](https://img.shields.io/badge/Workshop-Production_Ready-brightgreen)](https://github.com/databrickslabs/lakebridge)
[![Lakebridge Integration](https://img.shields.io/badge/Lakebridge-v0.10.9-blue)](https://github.com/databrickslabs/lakebridge)
[![Education](https://img.shields.io/badge/Purpose-Training_%26_Education-orange)](#learning-outcomes)

---

## üéØ Workshop Overview

This **comprehensive workshop** demonstrates practical SQL Server to Databricks migration using the powerful [Databricks Labs Lakebridge](https://github.com/databrickslabs/lakebridge) toolchain. Designed for migration teams, data architects, and business stakeholders, it provides **hands-on experience** through a realistic business scenario.

### **Business Scenario: GlobalSupply Corp** üè¢
Follow the fictional **GlobalSupply Corp** as they modernize their supply chain data warehouse from SQL Server to Databricks, enabling:
- ü§ñ **AI-powered supply chain optimization**
- üó£Ô∏è **Natural language queries for business users**
- üìä **Real-time analytics and forecasting**
- ‚òÅÔ∏è **Scalable cloud-native architecture**

### **Why This Workshop?**
While the official [Lakebridge tool](https://databrickslabs.github.io/lakebridge/) provides the technical foundation, this workshop bridges the gap between tool capabilities and real-world implementation by providing:
- **Business-aligned scenarios** with realistic SQL workloads
- **Strategic migration planning** based on complexity and risk
- **Hands-on exercises** that work with or without full Lakebridge setup
- **Executive reporting** with ROI calculations and business value demonstration

---

## üìö Workshop Modules

### **‚úÖ Module 1: Assessment & Analysis**
*Identify, analyze, and prioritize SQL workloads for migration*
- **Interactive Assessment**: Lakebridge analyzer with 8 realistic SQL files
- **Complexity Scoring**: Automated difficulty assessment (4.5-9.8/10 scale)
- **Migration Planning**: Wave-based strategy with effort estimates
- **Business Case**: ROI analysis and executive reporting

**Key Files**: `01_assessment_analyzer.py` ‚Ä¢ `01_assessment_notebook.ipynb` ‚Ä¢ `sample_sql/` (8 files)

### **‚úÖ Module 2: Schema Migration & Transpilation**
*Convert SQL Server workloads to Databricks SQL with strategic focus*
- **Automated Transpilation**: Lakebridge-powered conversion with manual fallbacks
- **Pattern Recognition**: 10 common SQL Server ‚Üí Databricks conversion patterns
- **Strategic Scope**: Focus on simple-medium complexity (48h vs 120h full scope)
- **Production Ready**: 3 validated Databricks SQL files with Unity Catalog schema

**Key Files**: `02_transpile_analyzer.py` ‚Ä¢ `02_manual_conversion_guide.sql` ‚Ä¢ `02_validation_tests.sql`

### **üìã Module 3: Data Reconciliation & Validation** *(Planned)*
*Validate accuracy and build confidence in migration results*
- **Automated Reconciliation**: Lakebridge reconcile functionality
- **Data Quality Assurance**: Comprehensive validation framework
- **Discrepancy Analysis**: Root cause analysis and remediation
- **Executive Reporting**: 99%+ accuracy validation with business confidence

**Estimated Effort**: ~30 hours ‚Ä¢ **Expected Outcome**: Production-ready validation framework

### **üìã Module 4: Modern Analytics & ML Integration** *(Planned)*
*Demonstrate advanced capabilities enabled by Databricks migration*
- **ML Pipeline Development**: Supply chain predictive models
- **Natural Language Queries**: Databricks Genie integration
- **Real-time Analytics**: Streaming supply chain monitoring
- **Executive Dashboards**: Traditional + predictive analytics unified

**Estimated Effort**: ~50 hours ‚Ä¢ **Expected Outcome**: $200K+ annual value demonstration

---

## üöÄ Quick Start Guide

### **Prerequisites**
```bash
# Core Requirements
python 3.10+
pip install pandas matplotlib seaborn openpyxl sqlparse

# Optional: Full Lakebridge Integration
databricks labs install lakebridge
databricks configure

# Databricks Workspace (recommended)
# Unity Catalog enabled
# SQL Warehouse configured
```

### **Running the Workshop**

#### **Option 1: Complete Workshop Experience**
```bash
# Clone this repository
git clone https://github.com/your-org/lakebridge-workshop.git
cd lakebridge-workshop

# Module 1: Assessment
cd workshop/01_assessment
python 01_assessment_analyzer.py --generate-samples
jupyter notebook 01_assessment_notebook.ipynb

# Module 2: Transpilation
cd ../02_transpilation
python 02_transpile_analyzer.py --source-directory ../01_assessment/sample_sql
jupyter notebook 02_transpilation_notebook.ipynb
```

#### **Option 2: Demo Mode (No Lakebridge Required)**
```bash
# Works without Lakebridge installation - uses sample data and manual examples
python 01_assessment_analyzer.py --generate-samples
python 02_transpile_analyzer.py --generate-samples
```

#### **Option 3: Production Integration**
```bash
# Use with your actual SQL Server workloads
python 01_assessment_analyzer.py --source-directory /path/to/your/sql
python 02_transpile_analyzer.py --source-directory /path/to/your/sql
```

---

## üíº Business Value Demonstration

### **Strategic Scope Management**
- **Cost Optimization**: $10,800 savings demonstrated through strategic file prioritization
- **Risk Mitigation**: Proven patterns (Wave 1 & 2) before advanced challenges (Wave 3)
- **Timeline Acceleration**: 48-hour focused scope vs 120-hour comprehensive approach

### **ROI Calculation Example**
```
Investment: 48 hours @ $150/hour = $7,200
Annual Benefits:
  ‚Ä¢ Performance Gains: 3-5x query improvement
  ‚Ä¢ Infrastructure Savings: 20-30% cost reduction
  ‚Ä¢ Advanced Analytics: ML-powered optimization
  ‚Ä¢ Total Annual Value: $200,000+

Payback Period: 1.3 months
3-Year ROI: 2,778%
```

### **Executive Reporting**
- **Migration Wave Strategy**: Risk-based prioritization
- **Effort Estimates**: Validated through practical implementation
- **Business Impact**: Quantified performance and cost benefits
- **Success Metrics**: 99%+ validation accuracy, measurable ROI

---

## üèóÔ∏è Technical Architecture

### **Workshop Structure**
```
lakebridge-workshop/
‚îú‚îÄ‚îÄ CLAUDE.md                     # Future Claude Code guidance
‚îú‚îÄ‚îÄ WORKSHOP_ROADMAP.md           # Modules 3 & 4 detailed planning
‚îú‚îÄ‚îÄ workshop/
‚îÇ   ‚îú‚îÄ‚îÄ 01_assessment/            # Module 1: Assessment & Analysis
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 01_assessment_analyzer.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 01_assessment_notebook.ipynb
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sample_sql/           # 8 realistic SQL files
‚îÇ   ‚îú‚îÄ‚îÄ 02_transpilation/         # Module 2: Schema Migration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 02_transpile_analyzer.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 02_manual_conversion_guide.sql
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 02_databricks_schema.sql
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 02_validation_tests.sql
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ transpiled_sql/       # Production-ready Databricks SQL
‚îÇ   ‚îú‚îÄ‚îÄ 03_reconciliation/        # Module 3: Data Validation (Planned)
‚îÇ   ‚îî‚îÄ‚îÄ 04_analytics/             # Module 4: Modern Analytics (Planned)
```

### **Integration with Lakebridge**
- **Assessment**: Uses `databricks labs lakebridge analyze` for complexity scoring
- **Transpilation**: Leverages `databricks labs lakebridge transpile` for automated conversion
- **Reconciliation**: Integrates `databricks labs lakebridge reconcile` for data validation
- **Fallback Support**: Manual examples when Lakebridge unavailable

### **Sample Data & Scenarios**
- **TPC-H Based**: Realistic supply chain data model
- **Complexity Range**: 4.5-9.8/10 covering simple reports to advanced analytics
- **Business Context**: Order processing, customer analytics, supplier management
- **Production Patterns**: Real-world SQL Server constructs and challenges

---

## üéì Learning Outcomes

### **Skills Developed**
- **Migration Planning**: Assessment-driven strategy and risk management
- **SQL Transpilation**: Automated tools + manual conversion patterns
- **Data Validation**: Reconciliation testing and quality assurance
- **Business Communication**: Executive reporting and ROI demonstration

### **Practical Capabilities**
- **Pattern Recognition**: 10 common SQL Server ‚Üí Databricks conversions
- **Tool Proficiency**: Lakebridge analyzer, transpiler, and reconciler
- **Quality Assurance**: Comprehensive validation and testing procedures
- **Performance Optimization**: Delta Lake and Unity Catalog best practices

### **Reusable Assets**
- **Pattern Library**: Common conversion templates
- **Validation Framework**: Extensible testing procedures
- **Schema Templates**: Unity Catalog structure patterns
- **Executive Templates**: Business case and ROI reporting

---

## üìä Workshop Statistics

### **Content Delivered**
- **24 Files**: 8,500+ lines of code and documentation
- **2 Interactive Notebooks**: Assessment and transpilation analysis
- **8 Sample SQL Files**: Realistic supply chain analytics (4.5-9.8 complexity)
- **3 Transpiled Files**: Production-ready Databricks SQL
- **Comprehensive Documentation**: Executive summaries, technical guides

### **Validation Results**
- **Strategic Focus**: 5 of 8 files (simple-medium complexity)
- **Cost Efficiency**: $10,800 cost avoidance through scope management
- **Quality Assurance**: Comprehensive test framework with 99%+ accuracy target
- **Timeline Management**: 2-3 week focused execution vs months for full scope

---

## ü§ù Attribution & Support

### **Built on Databricks Labs Lakebridge**
This workshop extends and demonstrates the capabilities of the official [Databricks Labs Lakebridge](https://github.com/databrickslabs/lakebridge) tool. For core Lakebridge functionality, documentation, and support:

- **Official Documentation**: https://databrickslabs.github.io/lakebridge/
- **Core Tool Repository**: https://github.com/databrickslabs/lakebridge
- **Lakebridge Issues**: Submit technical issues to the official repository

### **Workshop-Specific Support**
For workshop content, educational materials, and training scenarios:
- **Workshop Issues**: Submit to this repository's Issues tab
- **Educational Use**: Freely available for training and learning
- **Community Contributions**: Welcome! See contribution guidelines
- **Commercial Training**: Contact for enterprise workshop delivery

### **Project Status**
- **Workshop Status**: Production-ready for Modules 1 & 2
- **Lakebridge Integration**: Compatible with v0.10.9+
- **Educational Purpose**: Designed for team training and skill development
- **Community Support**: Best-effort support for educational use cases

---

## üìà Success Stories & Use Cases

### **Ideal Workshop Participants**
- **Migration Teams**: Hands-on experience with realistic scenarios
- **Data Architects**: Strategic planning and technical implementation
- **Business Stakeholders**: Understanding costs, benefits, and timelines
- **Consultants**: Reusable frameworks for client engagements

### **Workshop Applications**
- **Team Training**: Skill building for upcoming migrations
- **Proof of Concept**: Validate approach before large-scale implementation
- **Executive Alignment**: Demonstrate ROI and manage expectations
- **Pattern Development**: Build reusable conversion libraries

### **Expected Outcomes**
- **Technical Confidence**: Team ready for production migrations
- **Business Alignment**: Clear ROI and value proposition
- **Risk Mitigation**: Proven patterns and validation procedures
- **Accelerated Delivery**: Faster implementation through preparation

---

## üîó Additional Resources

### **Documentation**
- [`CLAUDE.md`](CLAUDE.md) - Guidance for future Claude Code instances
- [`WORKSHOP_ROADMAP.md`](WORKSHOP_ROADMAP.md) - Detailed Modules 3 & 4 planning
- [Module 1 Guide](workshop/01_assessment/) - Assessment and analysis procedures
- [Module 2 Guide](workshop/02_transpilation/) - Transpilation and validation

### **Official Lakebridge Resources**
- [Lakebridge Documentation](https://databrickslabs.github.io/lakebridge/)
- [Installation Guide](https://databrickslabs.github.io/lakebridge/installation/)
- [Contribution Guidelines](https://github.com/databrickslabs/lakebridge/blob/main/CONTRIBUTING.md)

### **Databricks Platform**
- [Unity Catalog Documentation](https://docs.databricks.com/data-governance/unity-catalog/)
- [Delta Lake Optimization Guide](https://docs.databricks.com/delta/optimizations/)
- [Databricks SQL Reference](https://docs.databricks.com/sql/language-manual/)

---

**üéâ Ready to transform your SQL Server workloads with confidence?**

*Start with Module 1 to assess your migration scope, continue to Module 2 for hands-on transpilation, then leverage the roadmap for advanced data reconciliation and ML capabilities.*

**[Get Started ‚Üí](workshop/01_assessment/)**